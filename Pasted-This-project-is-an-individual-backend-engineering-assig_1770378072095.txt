This project is an individual backend engineering assignment designed to evaluate real-world system design, performance optimization, and reliability under scale, inspired by real problems solved at FarmLokal. The goal is to build a production-grade backend service using Node.js with TypeScript, MySQL, Redis (mandatory), and optional Docker, deployed publicly on Render. The system must prioritize low latency, scalability, minimal database load, and clean architecture. AI tools may be used, but all implementation decisions must be defensible and explainable.

You will build this project on Replit using Node.js 18+. After creating a new Node.js Repl, initialize a TypeScript setup with typescript, ts-node-dev, and strict compiler options. The project should follow a clean modular architecture where responsibilities are clearly separated. The recommended structure includes configuration files for environment variables, Redis, MySQL, and OAuth; feature modules for authentication, products, and external integrations; middleware for rate limiting, authentication guards, and circuit breaking; and utility layers for retries, logging, and idempotency handling. This structure is important because judges explicitly evaluate clarity, maintainability, and architectural discipline.

All secrets such as database credentials, Redis URL, OAuth client credentials, and external API URLs must be stored using Replit Secrets. MySQL should be hosted externally using a managed provider such as PlanetScale, Railway, or Aiven, and Redis should be hosted using Upstash Redis to keep Replit compatibility simple and reliable.

Authentication must be implemented using the OAuth2 Client Credentials flow with any provider. Access tokens must never be fetched on every request. Instead, tokens must be cached in Redis with their expiry time. Token refresh must be concurrency-safe, meaning if multiple requests detect an expired token simultaneously, only one request should refresh it while others wait or reuse the refreshed value. This is typically achieved using a Redis lock or atomic operation. This part is heavily evaluated because it demonstrates real-world distributed system thinking.

The backend must integrate with two external APIs. The first is a synchronous API that your service calls directly. This integration must include strict timeout handling, retries with exponential backoff, and a circuit breaker to prevent cascading failures when the external service is down. The second integration must simulate a webhook or callback-based API. Webhook handling must be idempotent, meaning duplicate events must not be processed more than once. Redis must be used to store idempotency keys so that repeated webhook deliveries are safely acknowledged without reprocessing. Signature verification and safe retry handling are expected.

The core business API is a product listing endpoint exposed as GET /products. This endpoint must support cursor-based pagination (preferred over offset pagination), sorting, searching, and filtering, and it must be designed to scale to datasets with one million or more records. Cursor pagination should be based on indexed columns such as id or created_at, and cursors should be encoded to avoid exposing raw database values. MySQL indexing is critical here; indexes must exist on columns used for filtering, searching, sorting, and pagination. The endpoint must be optimized to use as few queries as possible, and Redis caching should be applied thoughtfully for frequently accessed query patterns, using hashed cache keys derived from query parameters with a reasonable TTL.

Performance and reliability are top priorities. At least two reliability techniques must be implemented, though implementing more will significantly strengthen the submission. These techniques include Redis-based caching, rate limiting using a sliding window or token bucket approach, circuit breakers for unstable dependencies, retry mechanisms with backoff, and request deduplication. Rate limiting should be enforced globally or per IP using Redis and should return proper HTTP 429 responses when limits are exceeded. All failures should be handled gracefully with meaningful error responses and logging.

The application must be deployed on Render. The GitHub repository should include a proper build command using npm install && npm run build and a start command using npm start. All environment variables used in Replit must be replicated in Render. The deployed service URL must be included in the final submission.

A detailed README.md is mandatory and plays a major role in evaluation. It must clearly explain the project overview, architecture decisions, authentication flow, Redis usage and caching strategy, database schema and indexing decisions, pagination strategy, performance optimizations, reliability techniques, trade-offs made, and instructions to run the project locally on Replit. Including an architecture diagram (even ASCII), example API requests, and reasoning behind design choices will strongly improve your score.

Judges primarily evaluate performance, scalability, and engineering judgment. They look for intelligent Redis usage rather than overuse, minimal database queries, clean separation of concerns, defensive coding practices, and clear explanations of why certain trade-offs were chosen. Bonus points are awarded for OpenAPI documentation, load testing scripts, database seed scripts for large datasets, and basic metrics or health endpoints.

This assignment is not about just making APIs work; it is about demonstrating how you think like a backend engineer working under real production constraints. Build it clean, explain it clearly, and optimize where it actually matters.